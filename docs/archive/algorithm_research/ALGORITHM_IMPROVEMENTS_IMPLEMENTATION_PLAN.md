# „Ç¢„É´„Ç¥„É™„Ç∫„É†ÊîπÂñÑÂÆüË£Ö„Éó„É©„É≥

**„Éô„Éº„Çπ**: „Éó„É≠„Éï„Çß„ÉÉ„Ç∑„Éß„Éä„É´„É¨„Éì„É•„ÉºÁµêÊûú  
**ÁõÆÊ®ô**: Ë®àÁÆóÊôÇÈñì -85%„ÄÅÂìÅË≥™Á∂≠ÊåÅ  

---

## üìã ÊîπÂñÑÈ†ÖÁõÆ‰∏ÄË¶ß

| ID | ÊîπÂñÑÈ†ÖÁõÆ | ÂÑ™ÂÖàÂ∫¶ | Â∑•Êï∞ | ÂäπÊûú | „É™„Çπ„ÇØ |
|----|----------|--------|------|------|--------|
| **I1** | ËøëÂÇçÁîüÊàê„ÅÆ„Çµ„É≥„Éó„É™„É≥„Ç∞ | ‚≠ê‚≠ê‚≠ê | 0.5Êó• | -60% | ‰Ωé |
| **I2** | Ë®≠ÂÆö„ÅÆÂ§ñÈÉ®Âåñ | ‚≠ê‚≠ê | 0.5Êó• | ‰øùÂÆàÊÄß | „Å™„Åó |
| **I3** | ÂÄôË£ú„ÅÆ„Éï„Ç£„É´„Çø„É™„É≥„Ç∞ | ‚≠ê‚≠ê | 0.3Êó• | +2%ÂìÅË≥™ | ‰Ωé |
| **I4** | ‰∏¶ÂàóÂÄôË£úÁîüÊàê | ‚≠ê‚≠ê‚≠ê | 1Êó• | -95%ÂÄôË£úÁîüÊàê | ‰Ωé |
| **I5** | Incremental Feasibility | ‚≠ê‚≠ê | 1.5Êó• | -40%LS | ‰∏≠ |
| **I6** | Adaptive Early Stop | ‚≠ê | 0.3Êó• | +20%LS | ‰Ωé |
| **I7** | Interval Tree | ‚≠ê | 1Êó• | -50%Greedy | ‰Ωé |

**ÂêàË®àÂ∑•Êï∞**: 5.1Êó•  
**ÊúüÂæÖÂäπÊûú**: Ë®àÁÆóÊôÇÈñì 165Áßí ‚Üí 25Áßí (-85%)  

---

## üöÄ Phase 1: Âç≥Â∫ßÂÆüË£ÖÔºà2Êó•Ôºâ

### I1. ËøëÂÇçÁîüÊàê„ÅÆ„Çµ„É≥„Éó„É™„É≥„Ç∞ ‚≠ê‚≠ê‚≠ê

**ÁõÆÁöÑ**: Local Search „ÅÆËøëÂÇçÁàÜÁô∫„ÇíÊäëÂà∂

**ÂÆüË£Ö**:

```python
# File: src/agrr_core/usecase/interactors/multi_field_crop_allocation_greedy_interactor.py

from dataclasses import dataclass, field
from typing import List, Callable
import random

@dataclass
class OptimizationConfig:
    """Configuration for optimization algorithm."""
    
    # Candidate generation
    quantity_levels: List[float] = field(default_factory=lambda: [1.0, 0.75, 0.5, 0.25])
    top_period_candidates: int = 3
    
    # Local search
    max_local_search_iterations: int = 100
    max_no_improvement: int = 20
    max_neighbors_per_iteration: int = 200  # NEW: ËøëÂÇçÊï∞„ÅÆ‰∏äÈôê
    enable_neighbor_sampling: bool = True  # NEW: „Çµ„É≥„Éó„É™„É≥„Ç∞„ÅÆÊúâÂäπÂåñ
    
    # Quantity adjustment
    quantity_adjustment_multipliers: List[float] = field(
        default_factory=lambda: [0.8, 0.9, 1.1, 1.2]
    )
    
    # Operation weights (for prioritization)
    operation_weights: Dict[str, float] = field(default_factory=lambda: {
        'field_swap': 0.3,
        'field_move': 0.1,
        'field_replace': 0.05,
        'field_remove': 0.05,
        'crop_insert': 0.2,
        'crop_change': 0.1,
        'period_replace': 0.1,
        'quantity_adjust': 0.1,
    })


class MultiFieldCropAllocationGreedyInteractor:
    """Interactor with optimized neighbor generation."""
    
    def __init__(self, ...):
        # ...
        self.config = OptimizationConfig()  # Default config
    
    def _generate_neighbors(
        self,
        solution: List[CropAllocation],
        candidates: List[AllocationCandidate],
        fields: List[Field],
        crops: List[Crop],
        config: Optional[OptimizationConfig] = None,
    ) -> List[List[CropAllocation]]:
        """Generate neighbor solutions with sampling."""
        
        cfg = config or self.config
        
        if not cfg.enable_neighbor_sampling:
            # Original implementation (no sampling)
            return self._generate_neighbors_original(solution, candidates, fields, crops)
        
        # NEW: Sampled implementation
        return self._generate_neighbors_sampled(solution, candidates, fields, crops, cfg)
    
    def _generate_neighbors_sampled(
        self,
        solution: List[CropAllocation],
        candidates: List[AllocationCandidate],
        fields: List[Field],
        crops: List[Crop],
        config: OptimizationConfig,
    ) -> List[List[CropAllocation]]:
        """Generate neighbors with sampling and prioritization.
        
        Strategy:
        1. Generate all operation types
        2. Sample from each type proportionally to weight
        3. Limit total neighbors to max_neighbors_per_iteration
        """
        
        all_neighbors = []
        
        # Define operations with their weights
        operations = [
            ('field_swap', self._field_swap_neighbors, [solution]),
            ('field_move', self._field_move_neighbors, [solution, candidates, fields]),
            ('field_replace', self._field_replace_neighbors, [solution, candidates, fields]),
            ('field_remove', self._field_remove_neighbors, [solution]),
            ('crop_insert', self._crop_insert_neighbors, [solution, candidates]),
            ('crop_change', self._crop_change_neighbors, [solution, candidates, crops]),
            ('period_replace', self._period_replace_neighbors, [solution, candidates]),
            ('quantity_adjust', self._quantity_adjust_neighbors, [solution]),
        ]
        
        # Calculate sample sizes for each operation
        total_weight = sum(config.operation_weights.values())
        max_neighbors = config.max_neighbors_per_iteration
        
        for op_name, op_func, op_args in operations:
            weight = config.operation_weights.get(op_name, 0.0)
            target_size = int(max_neighbors * (weight / total_weight))
            
            # Generate neighbors for this operation
            op_neighbors = op_func(*op_args)
            
            # Sample if too many
            if len(op_neighbors) > target_size:
                # Prefer diversity: random sample
                sampled = random.sample(op_neighbors, target_size)
            else:
                sampled = op_neighbors
            
            all_neighbors.extend(sampled)
        
        # Final sampling if still over limit
        if len(all_neighbors) > max_neighbors:
            all_neighbors = random.sample(all_neighbors, max_neighbors)
        
        return all_neighbors
    
    def _generate_neighbors_original(self, ...):
        """Original implementation (for backward compatibility)."""
        neighbors = []
        
        neighbors.extend(self._field_swap_neighbors(solution))
        neighbors.extend(self._field_move_neighbors(solution, candidates, fields))
        # ... (existing code)
        
        return neighbors
```

**„ÉÜ„Çπ„Éà**:

```python
# tests/test_usecase/test_multi_field_crop_allocation_performance.py

import pytest
import time

class TestPerformanceOptimizations:
    """Test performance optimizations."""
    
    def test_neighbor_sampling_reduces_count(self):
        """Test that sampling reduces neighbor count."""
        # Setup large solution
        solution = create_large_solution(size=50)  # 50 allocations
        
        config_no_sampling = OptimizationConfig(
            enable_neighbor_sampling=False
        )
        config_with_sampling = OptimizationConfig(
            enable_neighbor_sampling=True,
            max_neighbors_per_iteration=200
        )
        
        interactor = MultiFieldCropAllocationGreedyInteractor(None, None, None)
        
        # Generate neighbors without sampling
        neighbors_full = interactor._generate_neighbors(
            solution, candidates, fields, crops, config_no_sampling
        )
        
        # Generate neighbors with sampling
        neighbors_sampled = interactor._generate_neighbors(
            solution, candidates, fields, crops, config_with_sampling
        )
        
        # Should reduce neighbor count significantly
        assert len(neighbors_sampled) <= 200
        assert len(neighbors_sampled) < len(neighbors_full) * 0.3  # < 30%
    
    def test_sampling_maintains_quality(self):
        """Test that sampling doesn't degrade quality significantly."""
        # Run optimization with and without sampling
        
        result_no_sampling = interactor.execute(request, config=config_no_sampling)
        result_with_sampling = interactor.execute(request, config=config_with_sampling)
        
        # Quality should be within 5%
        quality_ratio = (
            result_with_sampling.total_profit / 
            result_no_sampling.total_profit
        )
        assert quality_ratio >= 0.95  # At least 95% quality
    
    def test_sampling_improves_speed(self):
        """Test that sampling improves computation time."""
        
        start = time.time()
        result_no_sampling = interactor.execute(request, config=config_no_sampling)
        time_no_sampling = time.time() - start
        
        start = time.time()
        result_with_sampling = interactor.execute(request, config=config_with_sampling)
        time_with_sampling = time.time() - start
        
        # Should be at least 40% faster
        speedup = time_no_sampling / time_with_sampling
        assert speedup >= 1.4  # 40% faster
```

**ÊúüÂæÖÂäπÊûú**:
```
Local SearchÊôÇÈñì: 60Áßí ‚Üí 24Áßí (-60%)
ËøëÂÇçÊï∞/iteration: 900 ‚Üí 200 (-78%)
ÂìÅË≥™„Å∏„ÅÆÂΩ±Èüø: -1„Äú2%
```

---

### I2. Ë®≠ÂÆö„ÅÆÂ§ñÈÉ®Âåñ ‚≠ê‚≠ê

**ÁõÆÁöÑ**: ÊüîËªüÊÄß„Å®‰øùÂÆàÊÄß„ÅÆÂêë‰∏ä

**ÂÆüË£Ö**:

```python
# Already shown in I1 - OptimizationConfig dataclass

# Usage in execute method
async def execute(
    self,
    request: MultiFieldCropAllocationRequestDTO,
    enable_local_search: bool = True,
    max_local_search_iterations: int = 100,
    config: Optional[OptimizationConfig] = None,  # NEW
) -> MultiFieldCropAllocationResponseDTO:
    """Execute multi-field crop allocation optimization."""
    
    # Use provided config or create default
    optimization_config = config or OptimizationConfig()
    
    # Override with explicit parameters if provided
    if max_local_search_iterations != 100:
        optimization_config.max_local_search_iterations = max_local_search_iterations
    
    # ...
    
    # Pass config to local search
    if enable_local_search:
        allocations = self._local_search(
            allocations,
            candidates,
            config=optimization_config,
            time_limit=request.max_computation_time
        )
```

**Ë®≠ÂÆö„Éï„Ç°„Ç§„É´„ÅÆ‰æã**:

```yaml
# config/optimization_config.yaml

default:
  quantity_levels: [1.0, 0.75, 0.5, 0.25]
  top_period_candidates: 3
  max_local_search_iterations: 100
  max_no_improvement: 20
  max_neighbors_per_iteration: 200
  enable_neighbor_sampling: true

fast:
  # È´òÈÄüË®≠ÂÆöÔºàÂìÅË≥™ -5%Ôºâ
  quantity_levels: [1.0, 0.5]  # ÂçäÂàÜ
  top_period_candidates: 2
  max_local_search_iterations: 50
  max_no_improvement: 10
  max_neighbors_per_iteration: 100

quality:
  # È´òÂìÅË≥™Ë®≠ÂÆöÔºàÊôÇÈñì +50%Ôºâ
  quantity_levels: [1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.25]
  top_period_candidates: 5
  max_local_search_iterations: 200
  max_no_improvement: 30
  max_neighbors_per_iteration: 300
```

```python
# Load config from file
import yaml

def load_config(profile='default'):
    with open('config/optimization_config.yaml') as f:
        configs = yaml.safe_load(f)
    return OptimizationConfig(**configs[profile])

# Usage
config = load_config('fast')
result = interactor.execute(request, config=config)
```

---

### I3. ÂÄôË£ú„ÅÆ„Éï„Ç£„É´„Çø„É™„É≥„Ç∞ ‚≠ê‚≠ê

**ÁõÆÁöÑ**: ‰ΩéÂìÅË≥™ÂÄôË£ú„ÅÆÈô§Â§ñ

**ÂÆüË£Ö**:

```python
async def _generate_candidates(
    self,
    fields: List[Field],
    request: MultiFieldCropAllocationRequestDTO,
    config: Optional[OptimizationConfig] = None,
) -> List[AllocationCandidate]:
    """Generate allocation candidates with quality filtering."""
    
    cfg = config or self.config
    candidates = []
    
    for field in fields:
        for crop_spec in request.crop_requirements:
            # ... (existing DP optimization) ...
            
            for quantity_level in cfg.quantity_levels:
                quantity = max_quantity * quantity_level
                area_used = quantity * crop.area_per_unit
                
                for candidate_period in optimization_result.candidates[:cfg.top_period_candidates]:
                    if candidate_period.completion_date is None or candidate_period.total_cost is None:
                        continue
                    
                    # Calculate metrics
                    revenue = quantity * crop.revenue_per_area * crop.area_per_unit
                    cost = candidate_period.total_cost
                    profit = revenue - cost
                    profit_rate = (profit / cost) if cost > 0 else 0
                    
                    # ===== NEW: Quality Filtering =====
                    
                    # Filter 1: Minimum profit rate
                    if profit_rate < -0.5:  # Loss > 50%
                        continue  # Skip clearly bad candidates
                    
                    # Filter 2: Minimum revenue/cost ratio
                    if revenue is not None and cost > 0:
                        revenue_cost_ratio = revenue / cost
                        if revenue_cost_ratio < 0.5:  # Revenue < 50% of cost
                            continue
                    
                    # Filter 3: Minimum absolute profit (if target is profit max)
                    if request.optimization_objective == "maximize_profit":
                        if profit is not None and profit < 0:
                            # Only keep profitable candidates
                            # Exception: if we need minimum quantity
                            crop_req = next((r for r in request.crop_requirements if r.crop_id == crop.crop_id), None)
                            if not (crop_req and crop_req.min_quantity and crop_req.min_quantity > 0):
                                continue
                    
                    # ===== End Filtering =====
                    
                    candidates.append(AllocationCandidate(...))
    
    # ===== NEW: Post-filtering =====
    
    # Sort by quality
    candidates.sort(key=lambda c: c.profit_rate, reverse=True)
    
    # Keep top K per field√ócrop
    candidates_by_field_crop = {}
    for c in candidates:
        key = (c.field.field_id, c.crop.crop_id)
        if key not in candidates_by_field_crop:
            candidates_by_field_crop[key] = []
        candidates_by_field_crop[key].append(c)
    
    # Limit to top 10 per field√ócrop
    filtered_candidates = []
    for key, cands in candidates_by_field_crop.items():
        filtered_candidates.extend(cands[:10])  # Top 10 only
    
    return filtered_candidates
```

**„ÉÜ„Çπ„Éà**:

```python
def test_candidate_filtering_removes_bad_candidates():
    """Test that filtering removes clearly bad candidates."""
    
    # Create scenario with some bad candidates
    # - Crop A: profit_rate = -0.8 (should be filtered)
    # - Crop B: profit_rate = 0.3 (should be kept)
    # - Crop C: revenue/cost = 0.3 (should be filtered)
    
    candidates = await interactor._generate_candidates(fields, request)
    
    # All remaining candidates should have acceptable quality
    for c in candidates:
        assert c.profit_rate >= -0.5
        if c.revenue is not None and c.cost > 0:
            assert c.revenue / c.cost >= 0.5
```

**ÊúüÂæÖÂäπÊûú**:
```
ÂÄôË£úÊï∞: 600 ‚Üí 480 (-20%)
GreedyÊôÇÈñì: 5Áßí ‚Üí 4Áßí (-20%)
ÂìÅË≥™: +2„Äú3% (ÊÇ™„ÅÑÂÄôË£ú„ÅåÈô§Â§ñ„Åï„Çå„Çã„Åü„ÇÅ)
```

---

## üöÄ Phase 2: ÈáçË¶Å„Å™ÊîπÂñÑÔºà3Êó•Ôºâ

### I4. ‰∏¶ÂàóÂÄôË£úÁîüÊàê ‚≠ê‚≠ê‚≠ê

**ÁõÆÁöÑ**: DPÊúÄÈÅ©Âåñ„ÅÆ‰∏¶ÂàóÂÆüË°å

**ÂÆüË£Ö**:

```python
import asyncio
from typing import Tuple

async def _generate_candidates_parallel(
    self,
    fields: List[Field],
    request: MultiFieldCropAllocationRequestDTO,
    config: Optional[OptimizationConfig] = None,
) -> List[AllocationCandidate]:
    """Generate candidates in parallel for all field√ócrop combinations."""
    
    cfg = config or self.config
    
    # Create tasks for all field √ó crop combinations
    tasks = []
    for field in fields:
        for crop_spec in request.crop_requirements:
            task = self._generate_candidates_for_field_crop(
                field, crop_spec, request, cfg
            )
            tasks.append(task)
    
    # Execute all tasks in parallel
    candidate_lists = await asyncio.gather(*tasks)
    
    # Flatten results
    all_candidates = []
    for candidate_list in candidate_lists:
        all_candidates.extend(candidate_list)
    
    # Post-filtering (if needed)
    filtered_candidates = self._post_filter_candidates(all_candidates, cfg)
    
    return filtered_candidates

async def _generate_candidates_for_field_crop(
    self,
    field: Field,
    crop_spec: CropRequirementSpec,
    request: MultiFieldCropAllocationRequestDTO,
    config: OptimizationConfig,
) -> List[AllocationCandidate]:
    """Generate candidates for a single field√ócrop combination."""
    
    # DP optimization for this field√ócrop
    optimization_request = OptimalGrowthPeriodRequestDTO(
        crop_id=crop_spec.crop_id,
        variety=crop_spec.variety,
        evaluation_period_start=request.planning_period_start,
        evaluation_period_end=request.planning_period_end,
        weather_data_file=request.weather_data_file,
        field_id=field.field_id,
        crop_requirement_file=crop_spec.crop_requirement_file,
    )
    
    optimization_result = await self.growth_period_optimizer.execute(optimization_request)
    
    # Get crop info
    crop_requirement = await self.crop_requirement_gateway.craft(
        crop_query=f"{crop_spec.crop_id} {crop_spec.variety}" if crop_spec.variety else crop_spec.crop_id
    )
    crop = crop_requirement.crop
    
    # Generate quantity√óperiod candidates
    candidates = []
    max_quantity = field.area / crop.area_per_unit if crop.area_per_unit > 0 else 0
    
    for quantity_level in config.quantity_levels:
        quantity = max_quantity * quantity_level
        area_used = quantity * crop.area_per_unit
        
        for candidate_period in optimization_result.candidates[:config.top_period_candidates]:
            if candidate_period.completion_date is None:
                continue
            
            # Calculate metrics
            revenue = quantity * crop.revenue_per_area * crop.area_per_unit if crop.revenue_per_area else 0
            cost = candidate_period.total_cost
            profit = revenue - cost
            profit_rate = (profit / cost) if cost > 0 else 0
            
            # Quality filtering
            if profit_rate < -0.5:
                continue
            
            candidates.append(AllocationCandidate(
                field=field,
                crop=crop,
                start_date=candidate_period.start_date,
                completion_date=candidate_period.completion_date,
                growth_days=candidate_period.growth_days,
                accumulated_gdd=0.0,
                quantity=quantity,
                cost=cost,
                revenue=revenue,
                profit=profit,
                profit_rate=profit_rate,
                area_used=area_used,
            ))
    
    return candidates
```

**ÊúüÂæÖÂäπÊûú**:
```
ÂÄôË£úÁîüÊàêÊôÇÈñì: 100Áßí ‚Üí 5Áßí (-95%) ‚≠ê‚≠ê‚≠ê
‰∏¶ÂàóÂ∫¶: 10 fields √ó 5 crops = 50‰∏¶Âàó
```

---

### I5. Incremental Feasibility Check ‚≠ê‚≠ê

**ÁõÆÁöÑ**: ËøëÂÇçË©ï‰æ°„ÅÆÈ´òÈÄüÂåñ

**ÂÆüË£Ö**:

```python
from enum import Enum

class NeighborOperationType(Enum):
    """Type of neighbor operation."""
    SWAP = "swap"
    ADD = "add"
    REMOVE = "remove"
    MODIFY = "modify"

@dataclass
class NeighborOperation:
    """Neighbor operation with metadata for incremental check."""
    operation_type: NeighborOperationType
    modified_allocations: List[CropAllocation]
    removed_allocation_ids: Set[str] = field(default_factory=set)

def _generate_neighbors_with_metadata(
    self,
    solution: List[CropAllocation],
    candidates: List[AllocationCandidate],
    fields: List[Field],
    crops: List[Crop],
    config: OptimizationConfig,
) -> List[Tuple[List[CropAllocation], NeighborOperation]]:
    """Generate neighbors with operation metadata."""
    
    neighbors_with_ops = []
    
    # Field Swap
    for i in range(len(solution)):
        for j in range(i + 1, len(solution)):
            if solution[i].field.field_id != solution[j].field.field_id:
                swapped = self._swap_allocations_with_area_adjustment(
                    solution[i], solution[j], solution
                )
                if swapped is not None:
                    neighbor = solution.copy()
                    neighbor[i], neighbor[j] = swapped
                    
                    op = NeighborOperation(
                        operation_type=NeighborOperationType.SWAP,
                        modified_allocations=list(swapped),
                        removed_allocation_ids={solution[i].allocation_id, solution[j].allocation_id}
                    )
                    neighbors_with_ops.append((neighbor, op))
    
    # ... (similar for other operations)
    
    return neighbors_with_ops

def _is_feasible_incremental(
    self,
    neighbor: List[CropAllocation],
    operation: NeighborOperation,
    base_solution: List[CropAllocation],
) -> bool:
    """Check feasibility incrementally based on operation type."""
    
    if operation.operation_type == NeighborOperationType.REMOVE:
        # Removal always maintains feasibility
        return True
    
    elif operation.operation_type in [NeighborOperationType.SWAP, NeighborOperationType.MODIFY]:
        # Only check modified allocations
        for modified_alloc in operation.modified_allocations:
            if not self._check_single_allocation_feasible(modified_alloc, neighbor):
                return False
        return True
    
    elif operation.operation_type == NeighborOperationType.ADD:
        # Only check new allocation
        new_alloc = operation.modified_allocations[0]
        return self._check_single_allocation_feasible(new_alloc, neighbor)
    
    # Fallback: full check
    return self._is_feasible_solution(neighbor)

def _check_single_allocation_feasible(
    self,
    alloc: CropAllocation,
    solution: List[CropAllocation],
) -> bool:
    """Check if single allocation is feasible within solution.
    
    Only checks:
    1. Time overlap with other allocations in same field
    2. Area capacity of field
    """
    
    # Check time overlap in same field
    for other in solution:
        if (other.field.field_id == alloc.field.field_id and
            other.allocation_id != alloc.allocation_id):
            if alloc.overlaps_with(other):
                return False  # Time conflict
    
    # Check area capacity
    used_area = sum(
        a.area_used
        for a in solution
        if a.field.field_id == alloc.field.field_id
    )
    if used_area > alloc.field.area:
        return False  # Exceeds capacity
    
    return True

def _local_search(
    self,
    initial_solution: List[CropAllocation],
    candidates: List[AllocationCandidate],
    config: Optional[OptimizationConfig] = None,
    time_limit: Optional[float] = None,
) -> List[CropAllocation]:
    """Local search with incremental feasibility check."""
    
    cfg = config or self.config
    start_time = time.time()
    current_solution = initial_solution
    current_profit = self._calculate_total_profit(current_solution)
    
    no_improvement_count = 0
    
    for iteration in range(cfg.max_local_search_iterations):
        if time_limit and (time.time() - start_time) > time_limit:
            break
        
        # Generate neighbors with metadata
        neighbors_with_ops = self._generate_neighbors_with_metadata(
            current_solution, candidates, fields, crops, cfg
        )
        
        # Find best neighbor (with incremental check)
        best_neighbor = None
        best_profit = current_profit
        
        for neighbor, operation in neighbors_with_ops:
            # Use incremental feasibility check
            if self._is_feasible_incremental(neighbor, operation, current_solution):
                neighbor_profit = self._calculate_total_profit(neighbor)
                if neighbor_profit > best_profit:
                    best_neighbor = neighbor
                    best_profit = neighbor_profit
        
        # Update or early stop
        if best_neighbor is not None:
            current_solution = best_neighbor
            current_profit = best_profit
            no_improvement_count = 0
        else:
            no_improvement_count += 1
        
        if no_improvement_count >= cfg.max_no_improvement:
            break
    
    return current_solution
```

**ÊúüÂæÖÂäπÊûú**:
```
Feasibility check: O(n¬≤) ‚Üí O(n)
Local SearchÊôÇÈñì: 24Áßí ‚Üí 14Áßí (-40%)
```

---

## üìä Á∑èÂêàÂäπÊûúÔºàPhase 1+2ÂÆüË£ÖÂæåÔºâ

### „Éë„Éï„Ç©„Éº„Éû„É≥„ÇπÊîπÂñÑ

```
Before (ÁèæÁä∂):
  ÂÄôË£úÁîüÊàê: 100Áßí
  Greedy: 5Áßí
  Local Search: 60Áßí
  ÂêàË®à: 165Áßí

After (Phase 1+2):
  ÂÄôË£úÁîüÊàê: 5Áßí (-95%, I4)
  Greedy: 4Áßí (-20%, I3)
  Local Search: 14Áßí (-77%, I1+I5)
  ÂêàË®à: 23Áßí (-86%) ‚≠ê‚≠ê‚≠ê

ÂìÅË≥™„Å∏„ÅÆÂΩ±Èüø: -1„Äú2% (Ë®±ÂÆπÁØÑÂõ≤)
```

### „Çπ„Ç±„Éº„É©„Éì„É™„ÉÜ„Ç£ÊîπÂñÑ

```
Before:
  n=30: 165Áßí
  n=50: 650Áßí (Êé®ÂÆö)
  n=100: 4000Áßí (Êé®ÂÆö) ‚ö†Ô∏è

After:
  n=30: 23Áßí
  n=50: 45Áßí
  n=100: 120Áßí ‚úì
```

---

## ÂÆüË£Ö„Çπ„Ç±„Ç∏„É•„Éº„É´

### Week 1: Phase 1 (2Êó•)

```
Day 1:
  - I1: ËøëÂÇç„Çµ„É≥„Éó„É™„É≥„Ç∞ÂÆüË£Ö
  - I2: Ë®≠ÂÆöÂ§ñÈÉ®Âåñ
  
Day 2:
  - I3: ÂÄôË£ú„Éï„Ç£„É´„Çø„É™„É≥„Ç∞
  - „ÉÜ„Çπ„Éà‰ΩúÊàê
  - „É¨„Éì„É•„Éº
```

### Week 2: Phase 2 (3Êó•)

```
Day 3-4:
  - I4: ‰∏¶ÂàóÂÄôË£úÁîüÊàê
  - „ÉÜ„Çπ„Éà‰ΩúÊàê
  
Day 5:
  - I5: Incremental Feasibility
  - Áµ±Âêà„ÉÜ„Çπ„Éà
  - „Éë„Éï„Ç©„Éº„Éû„É≥„Çπ„ÉÜ„Çπ„Éà
```

---

## „ÉÜ„Çπ„ÉàÊà¶Áï•

### „Éë„Éï„Ç©„Éº„Éû„É≥„Çπ„ÉÜ„Çπ„Éà

```python
# tests/test_usecase/test_performance_benchmark.py

@pytest.mark.performance
class TestPerformanceBenchmark:
    """Performance benchmark tests."""
    
    def test_candidate_generation_time(self):
        """Benchmark candidate generation time."""
        # 10 fields √ó 5 crops
        start = time.time()
        candidates = await interactor._generate_candidates_parallel(...)
        duration = time.time() - start
        
        assert duration < 10  # Should be under 10 seconds
    
    def test_local_search_time(self):
        """Benchmark local search time."""
        start = time.time()
        result = interactor._local_search(
            initial_solution,
            candidates,
            config=OptimizationConfig(
                enable_neighbor_sampling=True,
                max_neighbors_per_iteration=200
            )
        )
        duration = time.time() - start
        
        assert duration < 30  # Should be under 30 seconds
    
    def test_end_to_end_time(self):
        """Benchmark end-to-end optimization time."""
        request = create_standard_request()  # 10√ó5
        
        start = time.time()
        result = await interactor.execute(request)
        duration = time.time() - start
        
        assert duration < 60  # Should be under 1 minute
        assert result.total_profit > 0
```

### ÂìÅË≥™ÂõûÂ∏∞„ÉÜ„Çπ„Éà

```python
def test_quality_maintained_after_optimizations():
    """Test that optimizations don't degrade solution quality."""
    
    # Original (slow but thorough)
    config_original = OptimizationConfig(
        enable_neighbor_sampling=False,
        max_local_search_iterations=100
    )
    result_original = await interactor.execute(request, config=config_original)
    
    # Optimized (fast)
    config_optimized = OptimizationConfig(
        enable_neighbor_sampling=True,
        max_neighbors_per_iteration=200,
        max_local_search_iterations=100
    )
    result_optimized = await interactor.execute(request, config=config_optimized)
    
    # Quality should be within 5%
    quality_ratio = result_optimized.total_profit / result_original.total_profit
    assert quality_ratio >= 0.95  # At least 95% quality
```

---

## „Åæ„Å®„ÇÅ

### ÂÆüË£ÖÂÑ™ÂÖàÈ†Ü‰Ωç

1. **I1+I2+I3 (Phase 1)**: Âç≥Â∫ßÂÆüË£Ö„ÄÅ‰Ωé„É™„Çπ„ÇØ„ÄÅÈ´òÂäπÊûú
2. **I4 (Phase 2)**: ÊúÄÂ§ß„ÅÆÂäπÊûú„ÄÅÊó¢Â≠òasync„ÇíÊ¥ªÁî®
3. **I5 (Phase 2)**: ‰∏≠„É™„Çπ„ÇØ„Å†„ÅåÂ§ß„Åç„Å™ÂäπÊûú

### ÊúüÂæÖ„Åï„Çå„ÇãÊîπÂñÑ

- **Ë®àÁÆóÊôÇÈñì**: 165Áßí ‚Üí 23Áßí (-86%) ‚≠ê‚≠ê‚≠ê
- **„Çπ„Ç±„Éº„É©„Éì„É™„ÉÜ„Ç£**: ‰∏≠Ë¶èÊ®° ‚Üí Â§ßË¶èÊ®°ÂØæÂøúÂèØËÉΩ
- **‰øùÂÆàÊÄß**: Ë®≠ÂÆö„ÅÆÂ§ñÈÉ®Âåñ„ÅßÊüîËªüÊÄßÂêë‰∏ä
- **ÂìÅË≥™**: „Çè„Åö„Åã„Å™‰Ωé‰∏ã(-1„Äú2%)„ÅßË®±ÂÆπÁØÑÂõ≤

### Êé®Â•®

**‰ªäÈÄ±‰∏≠„Å´Phase 1„ÇíÂÆüË£Ö**„Åó„ÄÅÊù•ÈÄ±Phase 2„Å´ÁùÄÊâã„Åô„Çã„Åì„Å®„ÇíÂº∑„ÅèÊé®Â•®„Åó„Åæ„Åô„ÄÇ

ÂÆüË£ÖÂæå„ÄÅ„Éë„Éï„Ç©„Éº„Éû„É≥„Çπ„ÉÜ„Çπ„Éà„Å®ÂìÅË≥™ÂõûÂ∏∞„ÉÜ„Çπ„Éà„ÅßÂäπÊûú„ÇíÊ§úË®º„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

