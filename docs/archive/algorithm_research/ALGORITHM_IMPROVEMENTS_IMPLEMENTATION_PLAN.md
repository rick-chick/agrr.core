# ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æ”¹å–„å®Ÿè£…ãƒ—ãƒ©ãƒ³

**ãƒ™ãƒ¼ã‚¹**: ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœ  
**ç›®æ¨™**: è¨ˆç®—æ™‚é–“ -85%ã€å“è³ªç¶­æŒ  

---

## ğŸ“‹ æ”¹å–„é …ç›®ä¸€è¦§

| ID | æ”¹å–„é …ç›® | å„ªå…ˆåº¦ | å·¥æ•° | åŠ¹æœ | ãƒªã‚¹ã‚¯ |
|----|----------|--------|------|------|--------|
| **I1** | è¿‘å‚ç”Ÿæˆã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° | â­â­â­ | 0.5æ—¥ | -60% | ä½ |
| **I2** | è¨­å®šã®å¤–éƒ¨åŒ– | â­â­ | 0.5æ—¥ | ä¿å®ˆæ€§ | ãªã— |
| **I3** | å€™è£œã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° | â­â­ | 0.3æ—¥ | +2%å“è³ª | ä½ |
| **I4** | ä¸¦åˆ—å€™è£œç”Ÿæˆ | â­â­â­ | 1æ—¥ | -95%å€™è£œç”Ÿæˆ | ä½ |
| **I5** | Incremental Feasibility | â­â­ | 1.5æ—¥ | -40%LS | ä¸­ |
| **I6** | Adaptive Early Stop | â­ | 0.3æ—¥ | +20%LS | ä½ |
| **I7** | Interval Tree | â­ | 1æ—¥ | -50%Greedy | ä½ |

**åˆè¨ˆå·¥æ•°**: 5.1æ—¥  
**æœŸå¾…åŠ¹æœ**: è¨ˆç®—æ™‚é–“ 165ç§’ â†’ 25ç§’ (-85%)  

---

## ğŸš€ Phase 1: å³åº§å®Ÿè£…ï¼ˆ2æ—¥ï¼‰

### I1. è¿‘å‚ç”Ÿæˆã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° â­â­â­

**ç›®çš„**: Local Search ã®è¿‘å‚çˆ†ç™ºã‚’æŠ‘åˆ¶

**å®Ÿè£…**:

```python
# File: src/agrr_core/usecase/interactors/multi_field_crop_allocation_greedy_interactor.py

from dataclasses import dataclass, field
from typing import List, Callable
import random

@dataclass
class OptimizationConfig:
    """Configuration for optimization algorithm."""
    
    # Candidate generation
    quantity_levels: List[float] = field(default_factory=lambda: [1.0, 0.75, 0.5, 0.25])
    top_period_candidates: int = 3
    
    # Local search
    max_local_search_iterations: int = 100
    max_no_improvement: int = 20
    max_neighbors_per_iteration: int = 200  # NEW: è¿‘å‚æ•°ã®ä¸Šé™
    enable_neighbor_sampling: bool = True  # NEW: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®æœ‰åŠ¹åŒ–
    
    # Quantity adjustment
    quantity_adjustment_multipliers: List[float] = field(
        default_factory=lambda: [0.8, 0.9, 1.1, 1.2]
    )
    
    # Operation weights (for prioritization)
    operation_weights: Dict[str, float] = field(default_factory=lambda: {
        'field_swap': 0.3,
        'field_move': 0.1,
        'field_replace': 0.05,
        'field_remove': 0.05,
        'crop_insert': 0.2,
        'crop_change': 0.1,
        'period_replace': 0.1,
        'quantity_adjust': 0.1,
    })


class MultiFieldCropAllocationGreedyInteractor:
    """Interactor with optimized neighbor generation."""
    
    def __init__(self, ...):
        # ...
        self.config = OptimizationConfig()  # Default config
    
    def _generate_neighbors(
        self,
        solution: List[CropAllocation],
        candidates: List[AllocationCandidate],
        fields: List[Field],
        crops: List[Crop],
        config: Optional[OptimizationConfig] = None,
    ) -> List[List[CropAllocation]]:
        """Generate neighbor solutions with sampling."""
        
        cfg = config or self.config
        
        if not cfg.enable_neighbor_sampling:
            # Original implementation (no sampling)
            return self._generate_neighbors_original(solution, candidates, fields, crops)
        
        # NEW: Sampled implementation
        return self._generate_neighbors_sampled(solution, candidates, fields, crops, cfg)
    
    def _generate_neighbors_sampled(
        self,
        solution: List[CropAllocation],
        candidates: List[AllocationCandidate],
        fields: List[Field],
        crops: List[Crop],
        config: OptimizationConfig,
    ) -> List[List[CropAllocation]]:
        """Generate neighbors with sampling and prioritization.
        
        Strategy:
        1. Generate all operation types
        2. Sample from each type proportionally to weight
        3. Limit total neighbors to max_neighbors_per_iteration
        """
        
        all_neighbors = []
        
        # Define operations with their weights
        operations = [
            ('field_swap', self._field_swap_neighbors, [solution]),
            ('field_move', self._field_move_neighbors, [solution, candidates, fields]),
            ('field_replace', self._field_replace_neighbors, [solution, candidates, fields]),
            ('field_remove', self._field_remove_neighbors, [solution]),
            ('crop_insert', self._crop_insert_neighbors, [solution, candidates]),
            ('crop_change', self._crop_change_neighbors, [solution, candidates, crops]),
            ('period_replace', self._period_replace_neighbors, [solution, candidates]),
            ('quantity_adjust', self._quantity_adjust_neighbors, [solution]),
        ]
        
        # Calculate sample sizes for each operation
        total_weight = sum(config.operation_weights.values())
        max_neighbors = config.max_neighbors_per_iteration
        
        for op_name, op_func, op_args in operations:
            weight = config.operation_weights.get(op_name, 0.0)
            target_size = int(max_neighbors * (weight / total_weight))
            
            # Generate neighbors for this operation
            op_neighbors = op_func(*op_args)
            
            # Sample if too many
            if len(op_neighbors) > target_size:
                # Prefer diversity: random sample
                sampled = random.sample(op_neighbors, target_size)
            else:
                sampled = op_neighbors
            
            all_neighbors.extend(sampled)
        
        # Final sampling if still over limit
        if len(all_neighbors) > max_neighbors:
            all_neighbors = random.sample(all_neighbors, max_neighbors)
        
        return all_neighbors
    
    def _generate_neighbors_original(self, ...):
        """Original implementation (for backward compatibility)."""
        neighbors = []
        
        neighbors.extend(self._field_swap_neighbors(solution))
        neighbors.extend(self._field_move_neighbors(solution, candidates, fields))
        # ... (existing code)
        
        return neighbors
```

**ãƒ†ã‚¹ãƒˆ**:

```python
# tests/test_usecase/test_multi_field_crop_allocation_performance.py

import pytest
import time

class TestPerformanceOptimizations:
    """Test performance optimizations."""
    
    def test_neighbor_sampling_reduces_count(self):
        """Test that sampling reduces neighbor count."""
        # Setup large solution
        solution = create_large_solution(size=50)  # 50 allocations
        
        config_no_sampling = OptimizationConfig(
            enable_neighbor_sampling=False
        )
        config_with_sampling = OptimizationConfig(
            enable_neighbor_sampling=True,
            max_neighbors_per_iteration=200
        )
        
        interactor = MultiFieldCropAllocationGreedyInteractor(None, None, None)
        
        # Generate neighbors without sampling
        neighbors_full = interactor._generate_neighbors(
            solution, candidates, fields, crops, config_no_sampling
        )
        
        # Generate neighbors with sampling
        neighbors_sampled = interactor._generate_neighbors(
            solution, candidates, fields, crops, config_with_sampling
        )
        
        # Should reduce neighbor count significantly
        assert len(neighbors_sampled) <= 200
        assert len(neighbors_sampled) < len(neighbors_full) * 0.3  # < 30%
    
    def test_sampling_maintains_quality(self):
        """Test that sampling doesn't degrade quality significantly."""
        # Run optimization with and without sampling
        
        result_no_sampling = interactor.execute(request, config=config_no_sampling)
        result_with_sampling = interactor.execute(request, config=config_with_sampling)
        
        # Quality should be within 5%
        quality_ratio = (
            result_with_sampling.total_profit / 
            result_no_sampling.total_profit
        )
        assert quality_ratio >= 0.95  # At least 95% quality
    
    def test_sampling_improves_speed(self):
        """Test that sampling improves computation time."""
        
        start = time.time()
        result_no_sampling = interactor.execute(request, config=config_no_sampling)
        time_no_sampling = time.time() - start
        
        start = time.time()
        result_with_sampling = interactor.execute(request, config=config_with_sampling)
        time_with_sampling = time.time() - start
        
        # Should be at least 40% faster
        speedup = time_no_sampling / time_with_sampling
        assert speedup >= 1.4  # 40% faster
```

**æœŸå¾…åŠ¹æœ**:
```
Local Searchæ™‚é–“: 60ç§’ â†’ 24ç§’ (-60%)
è¿‘å‚æ•°/iteration: 900 â†’ 200 (-78%)
å“è³ªã¸ã®å½±éŸ¿: -1ã€œ2%
```

---

### I2. è¨­å®šã®å¤–éƒ¨åŒ– â­â­

**ç›®çš„**: æŸ”è»Ÿæ€§ã¨ä¿å®ˆæ€§ã®å‘ä¸Š

**å®Ÿè£…**:

```python
# Already shown in I1 - OptimizationConfig dataclass

# Usage in execute method
async def execute(
    self,
    request: MultiFieldCropAllocationRequestDTO,
    enable_local_search: bool = True,
    max_local_search_iterations: int = 100,
    config: Optional[OptimizationConfig] = None,  # NEW
) -> MultiFieldCropAllocationResponseDTO:
    """Execute multi-field crop allocation optimization."""
    
    # Use provided config or create default
    optimization_config = config or OptimizationConfig()
    
    # Override with explicit parameters if provided
    if max_local_search_iterations != 100:
        optimization_config.max_local_search_iterations = max_local_search_iterations
    
    # ...
    
    # Pass config to local search
    if enable_local_search:
        allocations = self._local_search(
            allocations,
            candidates,
            config=optimization_config,
            time_limit=request.max_computation_time
        )
```

**è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä¾‹**:

```yaml
# config/optimization_config.yaml

default:
  quantity_levels: [1.0, 0.75, 0.5, 0.25]
  top_period_candidates: 3
  max_local_search_iterations: 100
  max_no_improvement: 20
  max_neighbors_per_iteration: 200
  enable_neighbor_sampling: true

fast:
  # é«˜é€Ÿè¨­å®šï¼ˆå“è³ª -5%ï¼‰
  quantity_levels: [1.0, 0.5]  # åŠåˆ†
  top_period_candidates: 2
  max_local_search_iterations: 50
  max_no_improvement: 10
  max_neighbors_per_iteration: 100

quality:
  # é«˜å“è³ªè¨­å®šï¼ˆæ™‚é–“ +50%ï¼‰
  quantity_levels: [1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.25]
  top_period_candidates: 5
  max_local_search_iterations: 200
  max_no_improvement: 30
  max_neighbors_per_iteration: 300
```

```python
# Load config from file
import yaml

def load_config(profile='default'):
    with open('config/optimization_config.yaml') as f:
        configs = yaml.safe_load(f)
    return OptimizationConfig(**configs[profile])

# Usage
config = load_config('fast')
result = interactor.execute(request, config=config)
```

---

### I3. å€™è£œã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° â­â­

**ç›®çš„**: ä½å“è³ªå€™è£œã®é™¤å¤–

**å®Ÿè£…**:

```python
async def _generate_candidates(
    self,
    fields: List[Field],
    request: MultiFieldCropAllocationRequestDTO,
    config: Optional[OptimizationConfig] = None,
) -> List[AllocationCandidate]:
    """Generate allocation candidates with quality filtering."""
    
    cfg = config or self.config
    candidates = []
    
    for field in fields:
        for crop_spec in request.crop_requirements:
            # ... (existing DP optimization) ...
            
            for quantity_level in cfg.quantity_levels:
                quantity = max_quantity * quantity_level
                area_used = quantity * crop.area_per_unit
                
                for candidate_period in optimization_result.candidates[:cfg.top_period_candidates]:
                    if candidate_period.completion_date is None or candidate_period.total_cost is None:
                        continue
                    
                    # Calculate metrics
                    revenue = quantity * crop.revenue_per_area * crop.area_per_unit
                    cost = candidate_period.total_cost
                    profit = revenue - cost
                    profit_rate = (profit / cost) if cost > 0 else 0
                    
                    # ===== NEW: Quality Filtering =====
                    
                    # Filter 1: Minimum profit rate
                    if profit_rate < -0.5:  # Loss > 50%
                        continue  # Skip clearly bad candidates
                    
                    # Filter 2: Minimum revenue/cost ratio
                    if revenue is not None and cost > 0:
                        revenue_cost_ratio = revenue / cost
                        if revenue_cost_ratio < 0.5:  # Revenue < 50% of cost
                            continue
                    
                    # Filter 3: Minimum absolute profit (if target is profit max)
                    if request.optimization_objective == "maximize_profit":
                        if profit is not None and profit < 0:
                            # Only keep profitable candidates
                            # Exception: if we need minimum quantity
                            crop_req = next((r for r in request.crop_requirements if r.crop_id == crop.crop_id), None)
                            if not (crop_req and crop_req.min_quantity and crop_req.min_quantity > 0):
                                continue
                    
                    # ===== End Filtering =====
                    
                    candidates.append(AllocationCandidate(...))
    
    # ===== NEW: Post-filtering =====
    
    # Sort by quality
    candidates.sort(key=lambda c: c.profit_rate, reverse=True)
    
    # Keep top K per fieldÃ—crop
    candidates_by_field_crop = {}
    for c in candidates:
        key = (c.field.field_id, c.crop.crop_id)
        if key not in candidates_by_field_crop:
            candidates_by_field_crop[key] = []
        candidates_by_field_crop[key].append(c)
    
    # Limit to top 10 per fieldÃ—crop
    filtered_candidates = []
    for key, cands in candidates_by_field_crop.items():
        filtered_candidates.extend(cands[:10])  # Top 10 only
    
    return filtered_candidates
```

**ãƒ†ã‚¹ãƒˆ**:

```python
def test_candidate_filtering_removes_bad_candidates():
    """Test that filtering removes clearly bad candidates."""
    
    # Create scenario with some bad candidates
    # - Crop A: profit_rate = -0.8 (should be filtered)
    # - Crop B: profit_rate = 0.3 (should be kept)
    # - Crop C: revenue/cost = 0.3 (should be filtered)
    
    candidates = await interactor._generate_candidates(fields, request)
    
    # All remaining candidates should have acceptable quality
    for c in candidates:
        assert c.profit_rate >= -0.5
        if c.revenue is not None and c.cost > 0:
            assert c.revenue / c.cost >= 0.5
```

**æœŸå¾…åŠ¹æœ**:
```
å€™è£œæ•°: 600 â†’ 480 (-20%)
Greedyæ™‚é–“: 5ç§’ â†’ 4ç§’ (-20%)
å“è³ª: +2ã€œ3% (æ‚ªã„å€™è£œãŒé™¤å¤–ã•ã‚Œã‚‹ãŸã‚)
```

---

## ğŸš€ Phase 2: é‡è¦ãªæ”¹å–„ï¼ˆ3æ—¥ï¼‰

### I4. ä¸¦åˆ—å€™è£œç”Ÿæˆ â­â­â­

**ç›®çš„**: DPæœ€é©åŒ–ã®ä¸¦åˆ—å®Ÿè¡Œ

**å®Ÿè£…**:

```python
import asyncio
from typing import Tuple

async def _generate_candidates_parallel(
    self,
    fields: List[Field],
    request: MultiFieldCropAllocationRequestDTO,
    config: Optional[OptimizationConfig] = None,
) -> List[AllocationCandidate]:
    """Generate candidates in parallel for all fieldÃ—crop combinations."""
    
    cfg = config or self.config
    
    # Create tasks for all field Ã— crop combinations
    tasks = []
    for field in fields:
        for crop_spec in request.crop_requirements:
            task = self._generate_candidates_for_field_crop(
                field, crop_spec, request, cfg
            )
            tasks.append(task)
    
    # Execute all tasks in parallel
    candidate_lists = await asyncio.gather(*tasks)
    
    # Flatten results
    all_candidates = []
    for candidate_list in candidate_lists:
        all_candidates.extend(candidate_list)
    
    # Post-filtering (if needed)
    filtered_candidates = self._post_filter_candidates(all_candidates, cfg)
    
    return filtered_candidates

async def _generate_candidates_for_field_crop(
    self,
    field: Field,
    crop_spec: CropRequirementSpec,
    request: MultiFieldCropAllocationRequestDTO,
    config: OptimizationConfig,
) -> List[AllocationCandidate]:
    """Generate candidates for a single fieldÃ—crop combination."""
    
    # DP optimization for this fieldÃ—crop
    optimization_request = OptimalGrowthPeriodRequestDTO(
        crop_id=crop_spec.crop_id,
        variety=crop_spec.variety,
        evaluation_period_start=request.planning_period_start,
        evaluation_period_end=request.planning_period_end,
        weather_data_file=request.weather_data_file,
        field_id=field.field_id,
        crop_requirement_file=crop_spec.crop_requirement_file,
    )
    
    optimization_result = await self.growth_period_optimizer.execute(optimization_request)
    
    # Get crop info
    crop_requirement = await self.crop_requirement_gateway.craft(
        crop_query=f"{crop_spec.crop_id} {crop_spec.variety}" if crop_spec.variety else crop_spec.crop_id
    )
    crop = crop_requirement.crop
    
    # Generate quantityÃ—period candidates
    candidates = []
    max_quantity = field.area / crop.area_per_unit if crop.area_per_unit > 0 else 0
    
    for quantity_level in config.quantity_levels:
        quantity = max_quantity * quantity_level
        area_used = quantity * crop.area_per_unit
        
        for candidate_period in optimization_result.candidates[:config.top_period_candidates]:
            if candidate_period.completion_date is None:
                continue
            
            # Calculate metrics
            revenue = quantity * crop.revenue_per_area * crop.area_per_unit if crop.revenue_per_area else 0
            cost = candidate_period.total_cost
            profit = revenue - cost
            profit_rate = (profit / cost) if cost > 0 else 0
            
            # Quality filtering
            if profit_rate < -0.5:
                continue
            
            candidates.append(AllocationCandidate(
                field=field,
                crop=crop,
                start_date=candidate_period.start_date,
                completion_date=candidate_period.completion_date,
                growth_days=candidate_period.growth_days,
                accumulated_gdd=0.0,
                quantity=quantity,
                cost=cost,
                revenue=revenue,
                profit=profit,
                profit_rate=profit_rate,
                area_used=area_used,
            ))
    
    return candidates
```

**æœŸå¾…åŠ¹æœ**:
```
å€™è£œç”Ÿæˆæ™‚é–“: 100ç§’ â†’ 5ç§’ (-95%) â­â­â­
ä¸¦åˆ—åº¦: 10 fields Ã— 5 crops = 50ä¸¦åˆ—
```

---

### I5. Incremental Feasibility Check â­â­

**ç›®çš„**: è¿‘å‚è©•ä¾¡ã®é«˜é€ŸåŒ–

**å®Ÿè£…**:

```python
from enum import Enum

class NeighborOperationType(Enum):
    """Type of neighbor operation."""
    SWAP = "swap"
    ADD = "add"
    REMOVE = "remove"
    MODIFY = "modify"

@dataclass
class NeighborOperation:
    """Neighbor operation with metadata for incremental check."""
    operation_type: NeighborOperationType
    modified_allocations: List[CropAllocation]
    removed_allocation_ids: Set[str] = field(default_factory=set)

def _generate_neighbors_with_metadata(
    self,
    solution: List[CropAllocation],
    candidates: List[AllocationCandidate],
    fields: List[Field],
    crops: List[Crop],
    config: OptimizationConfig,
) -> List[Tuple[List[CropAllocation], NeighborOperation]]:
    """Generate neighbors with operation metadata."""
    
    neighbors_with_ops = []
    
    # Field Swap
    for i in range(len(solution)):
        for j in range(i + 1, len(solution)):
            if solution[i].field.field_id != solution[j].field.field_id:
                swapped = self._swap_allocations_with_area_adjustment(
                    solution[i], solution[j], solution
                )
                if swapped is not None:
                    neighbor = solution.copy()
                    neighbor[i], neighbor[j] = swapped
                    
                    op = NeighborOperation(
                        operation_type=NeighborOperationType.SWAP,
                        modified_allocations=list(swapped),
                        removed_allocation_ids={solution[i].allocation_id, solution[j].allocation_id}
                    )
                    neighbors_with_ops.append((neighbor, op))
    
    # ... (similar for other operations)
    
    return neighbors_with_ops

def _is_feasible_incremental(
    self,
    neighbor: List[CropAllocation],
    operation: NeighborOperation,
    base_solution: List[CropAllocation],
) -> bool:
    """Check feasibility incrementally based on operation type."""
    
    if operation.operation_type == NeighborOperationType.REMOVE:
        # Removal always maintains feasibility
        return True
    
    elif operation.operation_type in [NeighborOperationType.SWAP, NeighborOperationType.MODIFY]:
        # Only check modified allocations
        for modified_alloc in operation.modified_allocations:
            if not self._check_single_allocation_feasible(modified_alloc, neighbor):
                return False
        return True
    
    elif operation.operation_type == NeighborOperationType.ADD:
        # Only check new allocation
        new_alloc = operation.modified_allocations[0]
        return self._check_single_allocation_feasible(new_alloc, neighbor)
    
    # Fallback: full check
    return self._is_feasible_solution(neighbor)

def _check_single_allocation_feasible(
    self,
    alloc: CropAllocation,
    solution: List[CropAllocation],
) -> bool:
    """Check if single allocation is feasible within solution.
    
    Only checks:
    1. Time overlap with other allocations in same field
    2. Area capacity of field
    """
    
    # Check time overlap in same field
    for other in solution:
        if (other.field.field_id == alloc.field.field_id and
            other.allocation_id != alloc.allocation_id):
            if alloc.overlaps_with(other):
                return False  # Time conflict
    
    # Check area capacity
    used_area = sum(
        a.area_used
        for a in solution
        if a.field.field_id == alloc.field.field_id
    )
    if used_area > alloc.field.area:
        return False  # Exceeds capacity
    
    return True

def _local_search(
    self,
    initial_solution: List[CropAllocation],
    candidates: List[AllocationCandidate],
    config: Optional[OptimizationConfig] = None,
    time_limit: Optional[float] = None,
) -> List[CropAllocation]:
    """Local search with incremental feasibility check."""
    
    cfg = config or self.config
    start_time = time.time()
    current_solution = initial_solution
    current_profit = self._calculate_total_profit(current_solution)
    
    no_improvement_count = 0
    
    for iteration in range(cfg.max_local_search_iterations):
        if time_limit and (time.time() - start_time) > time_limit:
            break
        
        # Generate neighbors with metadata
        neighbors_with_ops = self._generate_neighbors_with_metadata(
            current_solution, candidates, fields, crops, cfg
        )
        
        # Find best neighbor (with incremental check)
        best_neighbor = None
        best_profit = current_profit
        
        for neighbor, operation in neighbors_with_ops:
            # Use incremental feasibility check
            if self._is_feasible_incremental(neighbor, operation, current_solution):
                neighbor_profit = self._calculate_total_profit(neighbor)
                if neighbor_profit > best_profit:
                    best_neighbor = neighbor
                    best_profit = neighbor_profit
        
        # Update or early stop
        if best_neighbor is not None:
            current_solution = best_neighbor
            current_profit = best_profit
            no_improvement_count = 0
        else:
            no_improvement_count += 1
        
        if no_improvement_count >= cfg.max_no_improvement:
            break
    
    return current_solution
```

**æœŸå¾…åŠ¹æœ**:
```
Feasibility check: O(nÂ²) â†’ O(n)
Local Searchæ™‚é–“: 24ç§’ â†’ 14ç§’ (-40%)
```

---

## ğŸ“Š ç·åˆåŠ¹æœï¼ˆPhase 1+2å®Ÿè£…å¾Œï¼‰

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„

```
Before (ç¾çŠ¶):
  å€™è£œç”Ÿæˆ: 100ç§’
  Greedy: 5ç§’
  Local Search: 60ç§’
  åˆè¨ˆ: 165ç§’

After (Phase 1+2):
  å€™è£œç”Ÿæˆ: 5ç§’ (-95%, I4)
  Greedy: 4ç§’ (-20%, I3)
  Local Search: 14ç§’ (-77%, I1+I5)
  åˆè¨ˆ: 23ç§’ (-86%) â­â­â­

å“è³ªã¸ã®å½±éŸ¿: -1ã€œ2% (è¨±å®¹ç¯„å›²)
```

### ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£æ”¹å–„

```
Before:
  n=30: 165ç§’
  n=50: 650ç§’ (æ¨å®š)
  n=100: 4000ç§’ (æ¨å®š) âš ï¸

After:
  n=30: 23ç§’
  n=50: 45ç§’
  n=100: 120ç§’ âœ“
```

---

## å®Ÿè£…ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«

### Week 1: Phase 1 (2æ—¥)

```
Day 1:
  - I1: è¿‘å‚ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å®Ÿè£…
  - I2: è¨­å®šå¤–éƒ¨åŒ–
  
Day 2:
  - I3: å€™è£œãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
  - ãƒ†ã‚¹ãƒˆä½œæˆ
  - ãƒ¬ãƒ“ãƒ¥ãƒ¼
```

### Week 2: Phase 2 (3æ—¥)

```
Day 3-4:
  - I4: ä¸¦åˆ—å€™è£œç”Ÿæˆ
  - ãƒ†ã‚¹ãƒˆä½œæˆ
  
Day 5:
  - I5: Incremental Feasibility
  - çµ±åˆãƒ†ã‚¹ãƒˆ
  - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
```

---

## ãƒ†ã‚¹ãƒˆæˆ¦ç•¥

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ

```python
# tests/test_usecase/test_performance_benchmark.py

@pytest.mark.performance
class TestPerformanceBenchmark:
    """Performance benchmark tests."""
    
    def test_candidate_generation_time(self):
        """Benchmark candidate generation time."""
        # 10 fields Ã— 5 crops
        start = time.time()
        candidates = await interactor._generate_candidates_parallel(...)
        duration = time.time() - start
        
        assert duration < 10  # Should be under 10 seconds
    
    def test_local_search_time(self):
        """Benchmark local search time."""
        start = time.time()
        result = interactor._local_search(
            initial_solution,
            candidates,
            config=OptimizationConfig(
                enable_neighbor_sampling=True,
                max_neighbors_per_iteration=200
            )
        )
        duration = time.time() - start
        
        assert duration < 30  # Should be under 30 seconds
    
    def test_end_to_end_time(self):
        """Benchmark end-to-end optimization time."""
        request = create_standard_request()  # 10Ã—5
        
        start = time.time()
        result = await interactor.execute(request)
        duration = time.time() - start
        
        assert duration < 60  # Should be under 1 minute
        assert result.total_profit > 0
```

### å“è³ªå›å¸°ãƒ†ã‚¹ãƒˆ

```python
def test_quality_maintained_after_optimizations():
    """Test that optimizations don't degrade solution quality."""
    
    # Original (slow but thorough)
    config_original = OptimizationConfig(
        enable_neighbor_sampling=False,
        max_local_search_iterations=100
    )
    result_original = await interactor.execute(request, config=config_original)
    
    # Optimized (fast)
    config_optimized = OptimizationConfig(
        enable_neighbor_sampling=True,
        max_neighbors_per_iteration=200,
        max_local_search_iterations=100
    )
    result_optimized = await interactor.execute(request, config=config_optimized)
    
    # Quality should be within 5%
    quality_ratio = result_optimized.total_profit / result_original.total_profit
    assert quality_ratio >= 0.95  # At least 95% quality
```

---

## ã¾ã¨ã‚

### å®Ÿè£…å„ªå…ˆé †ä½

1. **I1+I2+I3 (Phase 1)**: å³åº§å®Ÿè£…ã€ä½ãƒªã‚¹ã‚¯ã€é«˜åŠ¹æœ
2. **I4 (Phase 2)**: æœ€å¤§ã®åŠ¹æœã€æ—¢å­˜asyncã‚’æ´»ç”¨
3. **I5 (Phase 2)**: ä¸­ãƒªã‚¹ã‚¯ã ãŒå¤§ããªåŠ¹æœ

### æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„

- **è¨ˆç®—æ™‚é–“**: 165ç§’ â†’ 23ç§’ (-86%) â­â­â­
- **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**: ä¸­è¦æ¨¡ â†’ å¤§è¦æ¨¡å¯¾å¿œå¯èƒ½
- **ä¿å®ˆæ€§**: è¨­å®šã®å¤–éƒ¨åŒ–ã§æŸ”è»Ÿæ€§å‘ä¸Š
- **å“è³ª**: ã‚ãšã‹ãªä½ä¸‹(-1ã€œ2%)ã§è¨±å®¹ç¯„å›²

### æ¨å¥¨

**ä»Šé€±ä¸­ã«Phase 1ã‚’å®Ÿè£…**ã—ã€æ¥é€±Phase 2ã«ç€æ‰‹ã™ã‚‹ã“ã¨ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚

å®Ÿè£…å¾Œã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã¨å“è³ªå›å¸°ãƒ†ã‚¹ãƒˆã§åŠ¹æœã‚’æ¤œè¨¼ã—ã¦ãã ã•ã„ã€‚

